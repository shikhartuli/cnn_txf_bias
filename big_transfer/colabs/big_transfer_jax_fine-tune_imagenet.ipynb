{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"big_transfer_jax_fine-tune_imagenet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sXhZm0kpPpH6"},"source":["##### Copyright 2020 Google LLC."]},{"cell_type":"code","metadata":{"cellView":"form","id":"KfmzfvFxPuk7"},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iOVCm4CnP1Do"},"source":["<a href=\"https://colab.research.google.com/github/google-research/big_transfer/blob/master/colabs/big_transfer_jax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"Q9nosNf1PdEL"},"source":["# Install flax and run imports"]},{"cell_type":"code","metadata":{"id":"zZvI8OXt78sj","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1609065603949,"user_tz":-330,"elapsed":27830,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}},"outputId":"14404187-1ddb-4fb5-8683-4be813474fef"},"source":["#@markdown Select whether you would like to store data in your personal drive.\n","#@markdown\n","#@markdown If you select **yes**, you will need to authorize Colab to access\n","#@markdown your personal drive\n","#@markdown\n","#@markdown If you select **no**, then any changes you make will diappear when\n","#@markdown this Colab's VM restarts after some time of inactivity...\n","use_gdrive = 'yes'  #@param [\"yes\", \"no\"]\n","\n","if use_gdrive == 'yes':\n","  from google.colab import drive\n","  drive.mount('/gdrive')\n","  root = '/gdrive/My Drive/Fall 20-21/COS 454/Project/cnn_txf_bias/big_transfer'\n","  import os\n","  if not os.path.isdir(root):\n","    os.mkdir(root)\n","  os.chdir(root)\n","  print(f'\\nChanged CWD to \"{root}\"')\n","else:\n","  from IPython import display\n","  display.display(display.HTML(\n","      '<h1 style=\"color:red\">CHANGES NOT PERSISTED</h1>'))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n","\n","Changed CWD to \"/gdrive/My Drive/Fall 20-21/COS 454/Project/cnn_txf_bias/big_transfer\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2MCUeLqhqh6d","executionInfo":{"status":"ok","timestamp":1609065631439,"user_tz":-330,"elapsed":17951,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}},"outputId":"0442d3c4-bb15-4a53-ab64-9488d3d6892e"},"source":["!pip install flax\n","!pip install tfa-nightly\n","!pip install tensorflow_io\n","!pip install tfds-nightly"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting flax\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/c0/941b4d2a2164c677fe665b6ddb5ac90306d76f8ffc298f44c41c64b30f1a/flax-0.3.0-py3-none-any.whl (154kB)\n","\r\u001b[K     |██▏                             | 10kB 27.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 32.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 30kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 40kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 51kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 61kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 71kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 81kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 92kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 102kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 112kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 122kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 133kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 143kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 153kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 12.6MB/s \n","\u001b[?25hRequirement already satisfied: jax>=0.2.6 in /usr/local/lib/python3.6/dist-packages (from flax) (0.2.7)\n","Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from flax) (1.19.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from flax) (3.2.2)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from flax) (1.0.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from flax) (0.8)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from jax>=0.2.6->flax) (0.10.0)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from jax>=0.2.6->flax) (3.3.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax) (1.3.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->jax>=0.2.6->flax) (1.15.0)\n","Installing collected packages: flax\n","Successfully installed flax-0.3.0\n","Collecting tfa-nightly\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/e2/dcaf2a04d3e35453b581fa6aeb4601e8a3972f10af28a96f362e26fd25d6/tfa_nightly-0.13.0.dev20201223200403-cp36-cp36m-manylinux2010_x86_64.whl (703kB)\n","\u001b[K     |████████████████████████████████| 706kB 12.9MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tfa-nightly) (2.7.1)\n","Installing collected packages: tfa-nightly\n","Successfully installed tfa-nightly-0.13.0.dev20201223200403\n","Collecting tensorflow_io\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/3c/b45c30448cd6a04f25b088da024229149323fa44bc6322a7372bb556eada/tensorflow_io-0.17.0-cp36-cp36m-manylinux2010_x86_64.whl (25.3MB)\n","\u001b[K     |████████████████████████████████| 25.3MB 136kB/s \n","\u001b[?25hRequirement already satisfied: tensorflow<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_io) (2.4.0)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (2.4.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (0.3.3)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.32.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (3.12.4)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.12)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (0.36.2)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (3.3.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.12.1)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (2.4.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.6.3)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.19.4)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (3.7.4.3)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (2.10.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (0.10.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.1.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.1.2)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (0.2.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (51.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (3.3.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (2.23.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.17.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (0.4.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.7.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (3.3.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (2020.12.5)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (4.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (4.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (1.3.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (3.4.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow_io) (3.1.0)\n","Installing collected packages: tensorflow-io\n","Successfully installed tensorflow-io-0.17.0\n","Collecting tfds-nightly\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/57/6695aa374ba977c7a64d1363d1977002e32b90fd0c14cfaef03b9e8c5208/tfds_nightly-4.1.0.dev202012270106-py3-none-any.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 15.9MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (3.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.16.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (20.3.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (4.41.1)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.10.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (2.3)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.3.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.19.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (2.23.0)\n","Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (3.12.4)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.26.0)\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (3.7.4.3)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.15.0)\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tfds-nightly) (3.4.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (3.0.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.2->tfds-nightly) (51.0.0)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tfds-nightly) (1.52.0)\n","Installing collected packages: tfds-nightly\n","Successfully installed tfds-nightly-4.1.0.dev202012270106\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MKHdxUTJRiUF","executionInfo":{"status":"ok","timestamp":1609065720664,"user_tz":-330,"elapsed":5237,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}}},"source":["import io\n","import re\n","\n","from functools import partial\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","import random\n","\n","import jax\n","import jax.numpy as jnp\n","\n","import flax\n","import flax.nn as nn\n","import flax.optim as optim\n","import flax.jax_utils as flax_utils\n","\n","# Assert that GPU is available\n","assert 'Gpu' in str(jax.devices())\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mWzT0g8x6feo"},"source":["# Architecture and function for transforming BiT weights to JAX to format"]},{"cell_type":"code","metadata":{"id":"NjTie1S4RwmE","executionInfo":{"status":"ok","timestamp":1609065726748,"user_tz":-330,"elapsed":1293,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}}},"source":["def fixed_padding(x, kernel_size):\n","  pad_total = kernel_size - 1\n","  pad_beg = pad_total // 2\n","  pad_end = pad_total - pad_beg\n","\n","  x = jax.lax.pad(x, 0.0,\n","                  ((0, 0, 0),\n","                   (pad_beg, pad_end, 0), (pad_beg, pad_end, 0),\n","                   (0, 0, 0)))\n","  return x\n","\n","\n","def standardize(x, axis, eps):\n","  x = x - jnp.mean(x, axis=axis, keepdims=True)\n","  x = x / jnp.sqrt(jnp.mean(jnp.square(x), axis=axis, keepdims=True) + eps)\n","  return x\n","\n","\n","class GroupNorm(nn.Module):\n","  \"\"\"Group normalization (arxiv.org/abs/1803.08494).\"\"\"\n","\n","  def apply(self, x, num_groups=32):\n","\n","    input_shape = x.shape\n","    group_shape = x.shape[:-1] + (num_groups, x.shape[-1] // num_groups)\n","\n","    x = x.reshape(group_shape)\n","\n","    # Standardize along spatial and group dimensions\n","    x = standardize(x, axis=[1, 2, 4], eps=1e-5)\n","    x = x.reshape(input_shape)\n","\n","    bias_scale_shape = tuple([1, 1, 1] + [input_shape[-1]])\n","    x = x * self.param('scale', bias_scale_shape, nn.initializers.ones)\n","    x = x + self.param('bias', bias_scale_shape, nn.initializers.zeros)\n","    return x\n","\n","\n","class StdConv(nn.Conv):\n","\n","  def param(self, name, shape, initializer):\n","    param = super().param(name, shape, initializer)\n","    if name == 'kernel':\n","      param = standardize(param, axis=[0, 1, 2], eps=1e-10)\n","    return param\n","\n","\n","class RootBlock(nn.Module):\n","\n","  def apply(self, x, width):\n","    x = fixed_padding(x, 7)\n","    x = StdConv(x, width, (7, 7), (2, 2),\n","                padding=\"VALID\",\n","                bias=False,\n","                name=\"conv_root\")\n","\n","    x = fixed_padding(x, 3)\n","    x = nn.max_pool(x, (3, 3), strides=(2, 2), padding=\"VALID\")\n","\n","    return x\n","\n","\n","class ResidualUnit(nn.Module):\n","  \"\"\"Bottleneck ResNet block.\"\"\"\n","\n","  def apply(self, x, nout, strides=(1, 1)):\n","    x_shortcut = x\n","    needs_projection = x.shape[-1] != nout * 4 or strides != (1, 1)\n","\n","    group_norm = GroupNorm\n","    conv = StdConv.partial(bias=False)\n","\n","    x = group_norm(x, name=\"gn1\")\n","    x = nn.relu(x)\n","    if needs_projection:\n","      x_shortcut = conv(x, nout * 4, (1, 1), strides, name=\"conv_proj\")\n","    x = conv(x, nout, (1, 1), name=\"conv1\")\n","\n","    x = group_norm(x, name=\"gn2\")\n","    x = nn.relu(x)\n","    x = fixed_padding(x, 3)\n","    x = conv(x, nout, (3, 3), strides, name=\"conv2\", padding='VALID')\n","\n","    x = group_norm(x, name=\"gn3\")\n","    x = nn.relu(x)\n","    x = conv(x, nout * 4, (1, 1), name=\"conv3\")\n","\n","    return x + x_shortcut\n","\n","\n","class ResidualBlock(nn.Module):\n","\n","  def apply(self, x, block_size, nout, first_stride):\n","    x = ResidualUnit(\n","        x, nout, strides=first_stride,\n","        name=\"unit01\")\n","    for i in range(1, block_size):\n","      x = ResidualUnit(\n","          x, nout, strides=(1, 1),\n","          name=f\"unit{i+1:02d}\")\n","    return x\n","\n","\n","class ResNet(nn.Module):\n","  \"\"\"ResNetV2.\"\"\"\n","\n","  def apply(self, x, num_classes=1000,\n","            width_factor=1, num_layers=50):\n","    block_sizes = _block_sizes[num_layers]\n","\n","    width = 64 * width_factor\n","\n","    root_block = RootBlock.partial(width=width)\n","    x = root_block(x, name='root_block')\n","\n","    # Blocks\n","    for i, block_size in enumerate(block_sizes):\n","      x = ResidualBlock(x, block_size, width * 2 ** i,\n","                        first_stride=(1, 1) if i == 0 else (2, 2),\n","                        name=f\"block{i + 1}\")\n","\n","    # Pre-head\n","    x = GroupNorm(x, name='norm-pre-head')\n","    x = nn.relu(x)\n","    x = jnp.mean(x, axis=(1, 2))\n","\n","    # Head\n","    x = nn.Dense(x, num_classes, name=\"conv_head\",\n","                 kernel_init=nn.initializers.zeros)\n","\n","    return x.astype(jnp.float32)\n","\n","\n","_block_sizes = {\n","      50: [3, 4, 6, 3],\n","      101: [3, 4, 23, 3],\n","      152: [3, 8, 36, 3],\n","  }\n","\n","\n","def transform_params(params, params_tf, num_classes, init_head=False):\n","  # BiT and JAX models have different naming conventions, so we need to\n","  # properly map TF weights to JAX weights\n","  params['root_block']['conv_root']['kernel'] = (\n","    params_tf['resnet/root_block/standardized_conv2d/kernel'])\n","\n","  for block in ['block1', 'block2', 'block3', 'block4']:\n","    units = set([re.findall(r'unit\\d+', p)[0] for p in params_tf.keys()\n","                 if p.find(block) >= 0])\n","    for unit in units:\n","      for i, group in enumerate(['a', 'b', 'c']):\n","        params[block][unit][f'conv{i+1}']['kernel'] = (\n","          params_tf[f'resnet/{block}/{unit}/{group}/'\n","                    'standardized_conv2d/kernel'])\n","        params[block][unit][f'gn{i+1}']['bias'] = (\n","          params_tf[f'resnet/{block}/{unit}/{group}/'\n","                    'group_norm/beta'][None, None, None])\n","        params[block][unit][f'gn{i+1}']['scale'] = (\n","          params_tf[f'resnet/{block}/{unit}/{group}/'\n","                    'group_norm/gamma'][None, None, None])\n","\n","      projs = [p for p in params_tf.keys()\n","               if p.find(f'{block}/{unit}/a/proj') >= 0]\n","      assert len(projs) <= 1\n","      if projs:\n","        params[block][unit]['conv_proj']['kernel'] = params_tf[projs[0]]\n","\n","  params['norm-pre-head']['bias'] = (\n","    params_tf['resnet/group_norm/beta'][None, None, None])\n","  params['norm-pre-head']['scale'] = (\n","    params_tf['resnet/group_norm/gamma'][None, None, None])\n","\n","  if init_head:\n","    params['conv_head']['kernel'] = params_tf['resnet/head/conv2d/kernel'][0, 0]\n","    params['conv_head']['bias'] = params_tf['resnet/head/conv2d/bias']\n","  else:\n","    params['conv_head']['kernel'] = np.zeros(\n","      (params['conv_head']['kernel'].shape[0], num_classes), dtype=np.float32)\n","    params['conv_head']['bias'] = np.zeros(num_classes, dtype=np.float32)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b8NxYJ3QT5Nb"},"source":["# Run BiT-M-ResNet50x1"]},{"cell_type":"markdown","metadata":{"id":"oqI1eMG6QDJv"},"source":["## Build model and load weights"]},{"cell_type":"code","metadata":{"id":"EGNzuKlDS6yU","executionInfo":{"status":"ok","timestamp":1609066245558,"user_tz":-330,"elapsed":4341,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}}},"source":["with tf.io.gfile.GFile('gs://bit_models/BiT-M-R50x1-ILSVRC2012.npz', 'rb') as f:\n","  params_tf = np.load(f)\n","params_tf = dict(zip(params_tf.keys(), params_tf.values()))\n","\n","for k in params_tf:\n","  params_tf[k] = jnp.array(params_tf[k])\n","\n","ResNet_imagenet = ResNet.partial(num_classes=1000)\n","\n","def resnet_fn(params, images):\n","  return ResNet_imagenet.partial(num_classes=1000).call(params, images)\n","\n","resnet_init = ResNet_imagenet.init_by_shape\n","_, params = resnet_init(jax.random.PRNGKey(0), [([1, 224, 224, 3], jnp.float32)])\n","\n","transform_params(params, params_tf, 1000, init_head=True)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7plTTPh-QLtA"},"source":["## Prepare data"]},{"cell_type":"code","metadata":{"id":"EB1fRfiRVlz_","executionInfo":{"status":"ok","timestamp":1609066186443,"user_tz":-330,"elapsed":2771,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}}},"source":["data_builder = tfds.builder('imagenet2012', data_dir = '../vision_transformer/tensorflow_datasets_subset' )\n","data_builder.download_and_prepare()\n","\n","def _pp(data):\n","  im = data['image']\n","  im = tf.image.resize(im, [128, 128])\n","  im = (im - 127.5) / 127.5\n","  data['image'] = im\n","  return {'image': data['image'], 'label': data['label']}\n","\n","data = data_builder.as_dataset(split='validation')\n","data = data.map(_pp)\n","data = data.batch(100)\n","data_iter = data.as_numpy_iterator()"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y-jGg4cZU7HT"},"source":["## Run BiT"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9VdD7lqVl2V","executionInfo":{"status":"ok","timestamp":1609066533365,"user_tz":-330,"elapsed":287861,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}},"outputId":"7c0d31e7-7a73-4c92-ae0a-3b3835df6533"},"source":["correct, n = 0, 0\n","for batch in data_iter:\n","  preds = resnet_fn(params, batch['image'])\n","  correct += np.sum(np.argmax(preds, axis=1) == batch['label'])\n","  n += len(preds)\n","\n","print(f\"ImageNet accuracy of BiT-M-R50x1: {correct / n:0.3%}\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["ImageNet accuracy of BiT-M-R50x1: 46.391%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ddQ5crM0Qzdi"},"source":["# Run finetuning on ImageNet"]},{"cell_type":"markdown","metadata":{"id":"lHwHCUDfUfLc"},"source":["## Prepare data"]},{"cell_type":"code","metadata":{"id":"u4xd_uX1Vl5q","executionInfo":{"status":"ok","timestamp":1609066669400,"user_tz":-330,"elapsed":1405,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}}},"source":["data_builder = tfds.builder('imagenet2012', data_dir = '../vision_transformer/tensorflow_datasets_subset' )\n","data_builder.download_and_prepare()\n","\n","def get_data(split, repeats, batch_size, images_per_class, shuffle_buffer):\n","  data = data_builder.as_dataset(split=split)\n","\n","  if split == 'train':\n","    data = data.batch(50000)\n","\n","    data = data.as_numpy_iterator().next()\n","\n","    # np.random.seed(0)\n","    # indices = [idx \n","    #           for cls in range(10)\n","    #           for idx in np.random.choice(np.where(data['label'] == cls)[0],\n","    #                                       images_per_class,\n","    #                                       replace=False)]\n","\n","    # data = {'image': data['image'][indices],\n","    #         'label': data['label'][indices]}\n","\n","    data = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(data['image']),\n","                                tf.data.Dataset.from_tensor_slices(data['label'])))\n","    data = data.map(lambda x, y: {'image': x, 'label': y})\n","  else:\n","    data = data.map(lambda d: {'image': d['image'], 'label': d['label']})\n","\n","  def _pp(data):\n","    im = data['image']\n","    if split == 'train':\n","      im = tf.image.resize(im, [160, 160])\n","      im = tf.image.random_crop(im, [128, 128, 3])\n","      im = tf.image.flip_left_right(im)\n","    else:\n","      im = tf.image.resize(im, [128, 128])\n","    im = (im - 127.5) / 127.5\n","    data['image'] = im\n","    data['label'] = tf.one_hot(data['label'], 1000)\n","    return {'image': data['image'], 'label': data['label']}\n","\n","  data = data.repeat(repeats)\n","  data = data.shuffle(shuffle_buffer)\n","  data = data.map(_pp)\n","  return data.batch(batch_size)\n","\n","data_train = get_data(split='validation', repeats=None, images_per_class=None,\n","                      batch_size=256, shuffle_buffer=500)\n","data_test = get_data(split='validation', repeats=1, images_per_class=None,\n","                      batch_size=250, shuffle_buffer=1)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"88htJnbRUhGU"},"source":["## Build model and load weights"]},{"cell_type":"code","metadata":{"id":"P5eKHLdLWv9n","executionInfo":{"status":"ok","timestamp":1609070576274,"user_tz":-330,"elapsed":4487,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}}},"source":["@jax.jit\n","def resnet_fn(params, images):\n","  return ResNet.partial(num_classes=1000).call(params, images)\n","\n","def cross_entropy_loss(*, logits, labels):\n","  logp = jax.nn.log_softmax(logits)\n","  return -jnp.mean(jnp.sum(logp * labels, axis=1))\n","\n","def loss_fn(params, images, labels):\n","  logits = resnet_fn(params, images)\n","  return cross_entropy_loss(logits=logits, labels=labels)\n","\n","@jax.jit\n","def update_fn(opt, lr, images, labels):\n","  l, g = jax.value_and_grad(loss_fn)(opt.target, images, labels)\n","  opt = opt.apply_gradient(g, learning_rate=lr)\n","  return opt, l\n","\n","with tf.io.gfile.GFile('gs://bit_models/BiT-M-R50x1-ILSVRC2012.npz', 'rb') as f:\n","  params_tf = np.load(f)\n","params_tf = dict(zip(params_tf.keys(), params_tf.values()))\n","\n","resnet_init = ResNet.partial(num_classes=1000).init_by_shape\n","_, params = resnet_init(jax.random.PRNGKey(0), [([1, 224, 224, 3], jnp.float32)])\n","transform_params(params, params_tf, 1000, init_head=False)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kfvUYwKTUlRc"},"source":["## Run optimization"]},{"cell_type":"code","metadata":{"id":"4begAUoFWv65","executionInfo":{"status":"ok","timestamp":1609067527283,"user_tz":-330,"elapsed":1290,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}}},"source":["def get_lr(step):\n","  lr = 0.003\n","  if step < 100:\n","    return lr * (step / 100)\n","  else:\n","    for s in range(200, 1000, 100):\n","      if s < step:\n","        lr /= 10\n","    return lr"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwjsOz1bUWn_","executionInfo":{"status":"ok","timestamp":1609067530683,"user_tz":-330,"elapsed":1780,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}}},"source":["airplane_indices = [404]\n","bear_indices = [294, 295, 296, 297]\n","bicycle_indices = [444, 671]\n","bird_indices = [8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23,\n","                24, 80, 81, 82, 83, 87, 88, 89, 90, 91, 92, 93,\n","                94, 95, 96, 98, 99, 100, 127, 128, 129, 130, 131,\n","                132, 133, 135, 136, 137, 138, 139, 140, 141, 142,\n","                143, 144, 145]\n","boat_indices = [472, 554, 625, 814, 914]\n","bottle_indices = [440, 720, 737, 898, 899, 901, 907]\n","car_indices = [436, 511, 817]\n","cat_indices = [281, 282, 283, 284, 285, 286]\n","chair_indices = [423, 559, 765, 857]\n","clock_indices = [409, 530, 892]\n","dog_indices = [152, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n","                162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n","                172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n","                182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n","                193, 194, 195, 196, 197, 198, 199, 200, 201, 202,\n","                203, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n","                214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n","                224, 225, 226, 228, 229, 230, 231, 232, 233, 234,\n","                235, 236, 237, 238, 239, 240, 241, 243, 244, 245,\n","                246, 247, 248, 249, 250, 252, 253, 254, 255, 256,\n","                257, 259, 261, 262, 263, 265, 266, 267, 268]\n","elephant_indices = [385, 386] \n","keyboard_indices = [508, 878]\n","knife_indices = [499]\n","oven_indices = [766]\n","truck_indices = [555, 569, 656, 675, 717, 734, 864, 867]\n","\n","category_indices = [airplane_indices, bear_indices, bicycle_indices, bird_indices, boat_indices,\n","                    bottle_indices, car_indices, cat_indices, chair_indices, clock_indices,\n","                    dog_indices, elephant_indices, keyboard_indices, knife_indices,\n","                    oven_indices, truck_indices]"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDMxID3qWv4r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609083558986,"user_tz":-330,"elapsed":12979135,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}},"outputId":"1ecff255-98a0-464d-ed6a-88e93b658fe6"},"source":["import cv2\n","import csv\n","import re\n","import os\n","import sys\n","import tensorflow_addons as tfa\n","import pickle\n","if '../vision_transformer' not in sys.path:\n","  sys.path.append('../vision_transformer')\n","\n","# Adding simclr directory to path\n","if '../simclr' not in sys.path:\n","  sys.path.append('../simclr')\n","\n","# Importing data-augmentation functions\n","import data_util\n","\n","from vit_jax import checkpoint\n","import tensorflow_io as tfio\n","import tensorflow as tf\n","\n","labelnames = dict(\n","  # https://www.cs.toronto.edu/~kriz/cifar.html\n","  cifar10=('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'),\n","  # https://www.cs.toronto.edu/~kriz/cifar.html\n","  cifar100=('apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'computer_keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'),\n","  imagenet2012=tuple(open('ilsvrc2012_wordnet_lemmas.txt'))\n",")\n","dataset='imagenet2012'\n","\n","model = 'BiT-M-R50x1'\n","\n","opt = optim.Momentum(beta=0.9).create(params)\n","\n","tf.compat.v1.enable_eager_execution()\n","\n","experiments = ['Baseline', 'Rotate', 'Cutout', 'Sobel Filtering', 'Gaussian Blur', 'Color Distortion', 'Gaussain Noise']\n","\n","categories = os.listdir(\"./stimuli/cue-conflict/\")\n","categories.sort()\n","\n","acc_imagenet = []\n","shape_match = []\n","texture_match = []\n","shape_bias = []\n","\n","# Calculating total images in SIN-subset\n","total_images = 0\n","for c in categories:\n","  for im in os.listdir(\"./stimuli/cue-conflict/\" + c):\n","\n","    shape_label = c\n","    texture_label = re.search('-(.*).png', im).group(1)[:-1]\n","    total_images += 1\n","\n","for exp in range(0, len(experiments)):\n","  print(f'Running Experiment: {experiments[exp]}')\n","  if exp == 0:\n","    # Training loop\n","    for step, batch in zip(range(1000), data_train.as_numpy_iterator()):\n","      opt, loss_value = update_fn(\n","            opt, get_lr(step), batch[\"image\"], batch[\"label\"])\n","      if opt.state.step % 100 == 0:\n","        acc = np.mean([c for test_batch in data_test.as_numpy_iterator()\n","                      for c in (np.argmax(test_batch['label'], axis=1) ==\n","                                np.argmax(resnet_fn(opt.target, test_batch['image']), axis=1))])\n","        print(f\"\\rStep: {opt.state.step}, Test accuracy: {acc:0.3%}\", end=\"\")\n","\n","  if exp == 1:\n","    # Training loop\n","    for step, batch in zip(range(1000), data_train.as_numpy_iterator()):\n","      images, labels = batch['image'], batch['label']\n","      bi = tf.image.rot90(images, random.randint(1, 3))\n","      images = bi.numpy()\n","      batch_new = {'image': images, 'label': labels}\n","      opt, loss_value = update_fn(\n","            opt, get_lr(step), batch_new[\"image\"], batch_new[\"label\"])\n","      if opt.state.step % 100 == 0:\n","        acc = np.mean([c for test_batch in data_test.as_numpy_iterator()\n","                      for c in (np.argmax(test_batch['label'], axis=1) ==\n","                                np.argmax(resnet_fn(opt.target, test_batch['image']), axis=1))])\n","        print(f\"\\rStep: {opt.state.step}, Test accuracy: {acc:0.3%}\", end=\"\")\n","\n","  if exp == 2:\n","    # Training loop\n","    for step, batch in zip(range(1000), data_train.as_numpy_iterator()):\n","      images, labels = batch['image'], batch['label']\n","      bi = tfa.image.random_cutout(images, tuple([np.int32(random.randrange(2, 64, 2)), np.int32(random.randrange(2, 64, 2))]))\n","      images = bi.numpy()\n","      batch_new = {'image': images, 'label': labels}\n","      opt, loss_value = update_fn(\n","            opt, get_lr(step), batch_new[\"image\"], batch_new[\"label\"])\n","      if opt.state.step % 100 == 0:\n","        acc = np.mean([c for test_batch in data_test.as_numpy_iterator()\n","                      for c in (np.argmax(test_batch['label'], axis=1) ==\n","                                np.argmax(resnet_fn(opt.target, test_batch['image']), axis=1))])\n","        print(f\"\\rStep: {opt.state.step}, Test accuracy: {acc:0.3%}\", end=\"\")\n","\n","  if exp == 3:\n","    # Training loop\n","    for step, batch in zip(range(1000), data_train.as_numpy_iterator()):\n","      images, labels = batch['image'], batch['label']\n","      bi = tfio.experimental.filter.sobel(images)\n","      images = bi.numpy()\n","      batch_new = {'image': images, 'label': labels}\n","      opt, loss_value = update_fn(\n","            opt, get_lr(step), batch_new[\"image\"], batch_new[\"label\"])\n","      if opt.state.step % 100 == 0:\n","        acc = np.mean([c for test_batch in data_test.as_numpy_iterator()\n","                      for c in (np.argmax(test_batch['label'], axis=1) ==\n","                                np.argmax(resnet_fn(opt.target, test_batch['image']), axis=1))])\n","        print(f\"\\rStep: {opt.state.step}, Test accuracy: {acc:0.3%}\", end=\"\")\n","  \n","  if exp == 4:\n","    # Training loop\n","    for step, batch in zip(range(1000), data_train.as_numpy_iterator()):\n","      images, labels = batch['image'], batch['label']\n","      bi = tfa.image.gaussian_filter2d(images) #, filter_shape = [30, 30], sigma = 5)\n","      images = bi.numpy()\n","      opt, loss_value = update_fn(\n","            opt, get_lr(step), batch_new[\"image\"], batch_new[\"label\"])\n","      if opt.state.step % 100 == 0:\n","        acc = np.mean([c for test_batch in data_test.as_numpy_iterator()\n","                      for c in (np.argmax(test_batch['label'], axis=1) ==\n","                                np.argmax(resnet_fn(opt.target, test_batch['image']), axis=1))])\n","        print(f\"\\rStep: {opt.state.step}, Test accuracy: {acc:0.3%}\", end=\"\")\n","\n","  if exp == 5:\n","    # Training loop\n","    for step, batch in zip(range(1000), data_train.as_numpy_iterator()):\n","      images, labels = batch['image'], batch['label']\n","      for i in range(images.shape[0]):\n","        bi = data_util.color_jitter_nonrand(images[i], 0.1, 0.1, 0.1, 0.1)\n","        images[i] = bi\n","      batch_new = {'image': images, 'label': labels}\n","      opt, loss_value = update_fn(\n","            opt, get_lr(step), batch_new[\"image\"], batch_new[\"label\"])\n","      if opt.state.step % 100 == 0:\n","        acc = np.mean([c for test_batch in data_test.as_numpy_iterator()\n","                      for c in (np.argmax(test_batch['label'], axis=1) ==\n","                                np.argmax(resnet_fn(opt.target, test_batch['image']), axis=1))])\n","        print(f\"\\rStep: {opt.state.step}, Test accuracy: {acc:0.3%}\", end=\"\")\n","\n","  if exp == 6:\n","    # Training loop\n","    for step, batch in zip(range(1000), data_train.as_numpy_iterator()):\n","      images, labels = batch['image'], batch['label']\n","      bi = tf.clip_by_value(images + tf.random.normal(shape=tf.shape(images), mean=0.0, stddev=(50)/(255), dtype=tf.float32), 0.0, 1.0)\n","      images = bi.numpy()\n","      batch_new = {'image': images, 'label': labels}\n","      opt, loss_value = update_fn(\n","            opt, get_lr(step), batch_new[\"image\"], batch_new[\"label\"])\n","      if opt.state.step % 100 == 0:\n","        acc = np.mean([c for test_batch in data_test.as_numpy_iterator()\n","                      for c in (np.argmax(test_batch['label'], axis=1) ==\n","                                np.argmax(resnet_fn(opt.target, test_batch['image']), axis=1))])\n","        print(f\"\\rStep: {opt.state.step}, Test accuracy: {acc:0.3%}\", end=\"\")\n","\n","  print()      \n","\n","  exp_done = 'Baseline'\n","  for i in range(exp):\n","    exp_done = f'{exp_done}+{experiments[i+1]}'\n","  \n","  # Save model\n","  file_obj = open(f'./bit_models/imagenet21k+imagenet2012+imagenet2012/{model}_{exp_done}.pkl', 'wb')\n","  pickle.dump(opt.target, file_obj)\n","  file_obj.close()\n","\n","  # Accuracy on ImageNet\n","  print('Testing model on ImageNet')\n","  acc_imagenet.append(acc)\n","\n","  # file_obj = open(f'./bit_models/imagenet21k+imagenet2012+imagenet2012/{model}_{exp_done}.pkl', 'rb')\n","  # _, params_temp = resnet_init(jax.random.PRNGKey(0), [([1, 224, 224, 3], jnp.float32)])\n","  # transform_params(params_temp, pickle.load(file_obj), 1000, init_head=False)\n","  # file_obj.close()\n","\n","  count = 0\n","\n","  # SIN Test\n","  print('Running SIN Test')\n","  SIN_count = 0.0\n","  SIN_correct_shape = 0.0\n","  SIN_correct_texture = 0.0\n","  for c in categories:\n","    for im in os.listdir(\"./stimuli/cue-conflict/\" + c + \"/\"):\n","\n","      shape_label = c\n","      texture_label = re.search('-(.*).png', im).group(1)[:-1]\n","\n","      img = cv2.imread(\"./stimuli/cue-conflict/\" + c + \"/\" + im)\n","      img = cv2.resize(img, (384, 384))\n","      inp = (np.array(img) / 128 - 1)[None, ...]\n","\n","      logits, = resnet_fn(opt.target, inp)\n","      preds = flax.nn.softmax(logits)\n","\n","      preds_16 = np.zeros(16)\n","      for idx in range(1000):\n","        for ci in range(len(category_indices)):\n","          if idx in category_indices[ci]:\n","            preds_16[ci] += preds[idx]\n","\n","      try:\n","        SIN_correct_shape += 1 if (categories[preds_16.argsort()[-1]] == shape_label) else 0\n","      except:\n","        pass\n","      try:\n","        SIN_correct_texture += 1 if (categories[preds_16.argsort()[-1]] == texture_label) else 0\n","      except:\n","        pass\n","\n","      SIN_count += 1\n","\n","      count += 1\n","      print('\\r %0.2f%%' % (count/(total_images)*100), end='')\n","  \n","  print()\n","  \n","  shape_match.append(SIN_correct_shape / SIN_count)\n","  texture_match.append(SIN_correct_texture / SIN_count)\n","  shape_bias.append(shape_match[-1] / (texture_match[-1] + shape_match[-1]))\n","\n"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Running Experiment: Baseline\n","Step: 1000, Test accuracy: 78.064%\n","Testing model on ImageNet\n","Running SIN Test\n"," 100.00%\n","Running Experiment: Rotate\n","Step: 2000, Test accuracy: 72.774%\n","Testing model on ImageNet\n","Running SIN Test\n"," 100.00%\n","Running Experiment: Cutout\n","Step: 3000, Test accuracy: 88.070%\n","Testing model on ImageNet\n","Running SIN Test\n"," 100.00%\n","Running Experiment: Sobel Filtering\n","Step: 4000, Test accuracy: 69.296%\n","Testing model on ImageNet\n","Running SIN Test\n"," 100.00%\n","Running Experiment: Gaussian Blur\n","Step: 5000, Test accuracy: 59.856%\n","Testing model on ImageNet\n","Running SIN Test\n"," 100.00%\n","Running Experiment: Color Distortion\n","Step: 6000, Test accuracy: 77.346%\n","Testing model on ImageNet\n","Running SIN Test\n"," 100.00%\n","Running Experiment: Gaussain Noise\n","Step: 7000, Test accuracy: 76.844%\n","Testing model on ImageNet\n","Running SIN Test\n"," 100.00%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZHydBZw4Wl2K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609083688102,"user_tz":-330,"elapsed":1392,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}},"outputId":"89e7a10c-fc28-4631-bbd9-cade70b62063"},"source":["acc_imagenet, shape_match, texture_match, shape_bias"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.78064, 0.72774, 0.8807, 0.69296, 0.59856, 0.77346, 0.76844],\n"," [0.12265625,\n","  0.11640625,\n","  0.11796875,\n","  0.09375,\n","  0.0859375,\n","  0.10703125,\n","  0.1109375],\n"," [0.25703125, 0.253125, 0.240625, 0.2234375, 0.209375, 0.19375, 0.2015625],\n"," [0.32304526748971196,\n","  0.3150105708245243,\n","  0.3289760348583878,\n","  0.29556650246305416,\n","  0.29100529100529104,\n","  0.35584415584415585,\n","  0.355])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"SdiGQWmsYoDZ","executionInfo":{"status":"ok","timestamp":1609083757092,"user_tz":-330,"elapsed":1246,"user":{"displayName":"Shikhar Tuli","photoUrl":"","userId":"08476644503706754908"}}},"source":["with open(f'./results/fine-tune/imagenet2012/bit_fine-tune.csv', mode='w') as csv_file:\n","    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","\n","    csv_writer.writerow(['Augmentation', 'Shape Bias', 'Shape Match', 'Texture Match', 'CIFAR-10 Accuracy'])\n","    for exp in range(len(acc_imagenet)):\n","      aug = experiments[exp] if exp == 0 else f'+{experiments[exp]}'\n","      csv_writer.writerow([aug, f'{shape_bias[exp]*100}%', f'{shape_match[exp]*100}%', f'{texture_match[exp]*100}%', f'{acc_imagenet[exp]*100}%'])"],"execution_count":34,"outputs":[]}]}